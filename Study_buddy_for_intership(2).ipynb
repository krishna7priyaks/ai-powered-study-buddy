{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRgrgfxSn1pH",
        "outputId": "2cdf2c07-07d6-4319-94e2-c584cb27fa22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.21)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.11)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.21.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.40.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Study Buddy is ready!\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch sentencepiece gradio\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load AI pipelines\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
        "\n",
        "print(\"AI Study Buddy is ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- STUDY BUDDY FUNCTIONS ---------\n",
        "\n",
        "def summarize_notes(text):\n",
        "    summary = summarizer(text, max_length=150, min_length=60, do_sample=False)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "\n",
        "def create_flashcards(text):\n",
        "    prompt = f\"\"\"\n",
        "    Create 5 flashcards from the following notes.\n",
        "    Format:\n",
        "    Q: Question\n",
        "    A: Answer\n",
        "\n",
        "    Notes:\n",
        "    {text}\n",
        "    \"\"\"\n",
        "    result = generator(prompt, max_length=300)\n",
        "    return result[0]['generated_text']\n",
        "\n",
        "\n",
        "def generate_quiz(text):\n",
        "    prompt = f\"\"\"\n",
        "    Create a short quiz with 5 multiple choice questions from the notes below.\n",
        "    Provide correct answers at the end.\n",
        "\n",
        "    Notes:\n",
        "    {text}\n",
        "    \"\"\"\n",
        "    result = generator(prompt, max_length=400)\n",
        "    return result[0]['generated_text']\n",
        "\n",
        "\n",
        "print(\"Study Buddy features loaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC6Ahf5fqb4J",
        "outputId": "106c115d-bea7-4840-c9ab-318c43d7d564"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study Buddy features loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_flashcards(text):\n",
        "    prompt = f\"\"\"\n",
        "    Create 5 flashcards from the notes below.\n",
        "\n",
        "    Each flashcard should be in this format:\n",
        "    Question: ...\n",
        "    Answer: ...\n",
        "\n",
        "    Notes:\n",
        "    {text}\n",
        "    \"\"\"\n",
        "\n",
        "    result = generator(\n",
        "        prompt,\n",
        "        max_length=400,\n",
        "        do_sample=True,\n",
        "        temperature=0.8\n",
        "    )\n",
        "    return result[0]['generated_text']"
      ],
      "metadata": {
        "id": "6l6-R6yi_ABB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_quiz(text):\n",
        "    prompt = f\"\"\"\n",
        "    Based ONLY on the notes below, create 5 DIFFERENT multiple-choice questions.\n",
        "\n",
        "    Rules:\n",
        "    - Each question must test a different fact or idea\n",
        "    - Do NOT repeat the same question\n",
        "    - Each question must have 4 options (A, B, C, D)\n",
        "    - After each question, write: Correct answer: X\n",
        "\n",
        "    Notes:\n",
        "    {text}\n",
        "\n",
        "    Start now.\n",
        "    \"\"\"\n",
        "\n",
        "    result = generator(\n",
        "        prompt,\n",
        "        max_length=600,\n",
        "        do_sample=True,\n",
        "        temperature=1.0,\n",
        "        top_p=0.95\n",
        "    )\n",
        "    return result[0]['generated_text']"
      ],
      "metadata": {
        "id": "tfGnqeo9_D_x"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quiz_notes = \"\"\"\n",
        "Operating systems manage computer hardware and software resources.\n",
        "Examples include Windows, Linux, and macOS.\n",
        "Key functions include memory management, process scheduling, and file systems.\n",
        "\"\"\"\n",
        "\n",
        "print(generate_quiz(quiz_notes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te_ogDhUDIG0",
        "outputId": "0ed76ad7-8662-4df8-c111-8f8f29a51b6a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Which operating system has the most functions? (A, B, C, D). (B, C, D). (C, D). (D, A, B). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D). (A, B, C, D).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_notes = \"\"\"\n",
        "The explanation below is attributed to John McCarthy, who first coined the term “artificial intelligence” in 1956.\n",
        "\" It is the science and engineering of making intelligent machines, especially intelligent computer programs. It is related to the similar task of using computers to understand human intelligence, but AI does not have to confine itself to methods that are biologically observable.“\n",
        "\"\"\"\n",
        "\n",
        "print(\"SUMMARY:\\n\")\n",
        "print(summarize_notes(my_notes))\n",
        "\n",
        "print(\"\\nFLASHCARDS:\\n\")\n",
        "print(create_flashcards(my_notes))\n",
        "\n",
        "print(\"\\nQUIZ:\\n\")\n",
        "print(generate_quiz(my_notes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfU-VkytzvN3",
        "outputId": "936345b0-e6dc-49cc-c543-3f12adc82a3b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 150, but your input_length is only 81. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUMMARY:\n",
            "\n",
            "Artificial intelligence is the science and engineering of making intelligent machines, especially intelligent computer programs. It is related to the similar task of using computers to understand human intelligence, but AI does not have to confine itself to methods that are biologically observable. The explanation below is attributed to John McCarthy, who first coined the term “artificial intelligence” in 1956.\n",
            "\n",
            "FLASHCARDS:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=400) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is “artificial intelligence”?\n",
            "\n",
            "QUIZ:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Which of the following is TRUE according to the passage? (A) Artificial intelligence is the science and engineering of making intelligent machines, especially intelligent computer programs. (B) Artificial intelligence is related to the similar task of using computers to understand human intelligence, but AI does not have to confine itself to methods that are biologically observable. (C) Artificial intelligence is related to the similar task of using computers to understand human intelligence, but AI does not have to confine itself to methods that are biologically observable. (D) Artificial intelligence is related to the similar task of using computers to understand human intelligence, but AI does not have to confine itself to methods that are biologically observable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_notes = \"\"\"\n",
        "Machine Learning is a subset of Artificial Intelligence that focuses on\n",
        "algorithms that learn from data. It includes supervised learning,\n",
        "unsupervised learning, and reinforcement learning.\n",
        "\"\"\"\n",
        "\n",
        "print(\"SUMMARY:\\n\")\n",
        "print(summarize_notes(sample_notes))\n",
        "\n",
        "print(\"\\nFLASHCARDS:\\n\")\n",
        "print(create_flashcards(sample_notes))\n",
        "\n",
        "print(\"\\nQUIZ:\\n\")\n",
        "print(generate_quiz(sample_notes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOaqzyotAZT9",
        "outputId": "4198b6f5-7448-436e-db19-9ba0a6a85df5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 150, but your input_length is only 40. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUMMARY:\n",
            "\n",
            "Machine Learning is a subset of Artificial Intelligence that focuses ongorithms that learn from data. It includes supervised learning, unsupervised learning, and reinforcement learning. Machine Learning can be used to develop new products and services. For more information on Machine Learning, visit Machine Learning's official website. To learn more about Machine Learning on CNN.com click here.\n",
            "\n",
            "FLASHCARDS:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=400) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Machine Learning is a subset of Artificial Intelligence that focuses on algorithms that learn from data. It includes supervised learning, unsupervised learning, and reinforcement learning.\n",
            "\n",
            "QUIZ:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Which is the best title for the passage? ______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def study_buddy_app(notes):\n",
        "    summary = summarize_notes(notes)\n",
        "    flashcards = create_flashcards(notes)\n",
        "    quiz = generate_quiz(notes)\n",
        "    return summary, flashcards, quiz\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=study_buddy_app,\n",
        "    inputs=gr.Textbox(lines=10, placeholder=\"Paste your study notes here...\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(lines=6, label=\"Summary\"),\n",
        "        gr.Textbox(lines=10, label=\"Flashcards\"),\n",
        "        gr.Textbox(lines=12, label=\"Quiz\")\n",
        "    ],\n",
        "    title=\"AI-Powered Study Buddy\",\n",
        "    description=\"Summarizes notes, creates flashcards, and generates quizzes using AI\"\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "z86euhxAFMP-",
        "outputId": "aff48725-99b6-4c90-d8c2-509cb24a53d3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5f168a42abad2ae458.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5f168a42abad2ae458.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ]
}